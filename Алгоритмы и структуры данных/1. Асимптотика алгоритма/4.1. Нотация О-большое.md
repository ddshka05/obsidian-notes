## Упрощение функций временной эффективности

Упростим ещё сильнее!

В прошлом уроке мы выяснили, что временную эффективность алгоритма можно описать с помощью функции, которая размеру входных данных сопоставляет максимальное количество простейших операций, выполняемых внутри алгоритма. Например:

- $T(n) = 40 \log_2 n + 10$
- $T(n) = 100n^2 + 50n + 20\log_2 n + 220$

Функции временной эффективности зачастую достаточно точно описывают то, как изменяется время выполнения алгоритма по мере роста размера входных данных. Однако работать с этими функциями неудобно, так как они являются слишком сложными.

Чтобы упростить анализ времени выполнения алгоритмов, в теории алгоритмов было принято работать не с самой функцией, описывающей временную эффективность алгоритма, а с ее **верхней границей** – **функцией гораздо проще**:

Для обозначения верхней границы функции в математике существует специальная нотация: $O\text{-большое}$. В теории алгоритмов применяется именно она. Преимущество использования нотации $O\text{-большое}$ заключается в том, что она позволяет максимально упростить выражающую временную эффективность алгоритма функцию и сосредоточиться только на основных ее компонентах.

## Нотация $O\text{-большое}$
### Определение:

$\text{Пусть f, g: } \mathbb{N} \rightarrow \mathbb{N}$
$$\ (f(n) \in O(g(n)) := (\exists c > 0 \enspace \exists N \in \mathbb{N}: \forall n_0 \geq N \rightarrow f(n) \leq c \cdot g(n))$$

### Словесно
Говорят, что функция $f(n)$ есть $O(g(n))$, что записывается как $f(n)=O(g(n))$, если начиная с определенного значения аргумента $n_0$, значение функции $f(n)$ не превосходит значение функции $g(n)$, умноженное на некоторую постоянную величину $c$, то есть если существуют положительная константа $c$ и натуральная константа $n_0$ такие, что для всех $n_0 \geq N$выполняется неравенство $f(n) \leq c \cdot g(n)$

![[Pasted image 20250424192213.png]]

По графику видно, что начиная со значения аргумента $n_0$, значение функции $f(n)$ не превосходит значение функции $g(n)$, умноженное на определенную константу $c$. Это и говорит о том, что функция $f(n)$ есть $O(g(n))$, поскольку для функций $f(n)$ и $g(n)$ существуют константы $c$ и $n_0$ такие, что для всех $n_0 \geq N$ выполняется неравенство $f(n) \leq c \cdot g(n)$. 

### Суть
Нотация $O$-большое выражает, что начиная с определенного значения аргумента, значение одной функции всегда меньше или равно значению другой функции. Другими словами, **первая функция ограничена сверху второй функцией**.

### Нюансы 
1. Важно понимать, что запись $f(n) \in O(g(n))$ подразумевает то, что функция $f(n)$ ограничена сверху не обязательно на всей числовой оси, а лишь начиная с определенного значения аргумента, равного $n_0$​. При значениях аргумента $n_0 \geq N$ функция $f(n)$ может и не быть ограничена, однако нас эта область не интересует.

![[Pasted image 20250424193404.png]]

2. Нам не очень интересно поведение при небольших $n$, потому что эти варианты можно спокойно перебрать. Поэтому мы будем рассматривать $n \rightarrow \infty$. Будем тогда говорить о существенных $n$
3. Из определения понятно, что если существует два алгоритма, которые решают одну задачу за время $f(n), g(n)$, причем $f(n) \in O(g(n)$ (либо вместо принадлежности пишут $=$), то алгоритм $f(n)$ более эффективный, так как функция $f(n) \leq c \cdot g(n)$.
4. Отличие в любую положительную константу раз означает, что нам нет необходимости различать например $f(n) = 100n, g(n) = 200n$, потому что эта цифра перед $n$ зависит от мощности процессора, от его возможности в один такт совершать элементарных операций. 

## Свойства $O$-большое
#### Свойство 1
#### Утверждение:
$\text{Пусть f, g: } \mathbb{N} \rightarrow \mathbb{N}$
$\ (f(n) \in O(g(n)) := (\exists \hat{c} > 0: \forall n \in \mathbb{N} \rightarrow f(n) \leq \hat{c} \cdot g(n))$, т.е. $N$ не зависит от $c$, можно его подобрать под это $N$. 

$\Box$
"$\rightarrow$" $\ (f(n) \in O(g(n)) \rightarrow (\exists \hat{c} > 0: \forall n \in \mathbb{N} \rightarrow f(n) \leq \hat{c} \cdot g(n))$

Тогда нам дано, что $\forall n \geq N \rightarrow f(n) \leq c * g(n)$

Положим, что $\hat{c} = \max \{c, \frac{f(1)}{g(1)}, \frac{f(2)}{g(2)},..., \frac{f(N)}{f(N)}\}$, то есть максимальное из отношений функций во всех точках до $N$. Тогда для такого $\hat{c}$ верно правое. 

Докажем, что для любого $n: f(n) \leq \hat{c} \cdot g(n)$. 
Пусть $n \leq N$, тогда по построению $\hat{c} \geq \frac{f(n)}{g(n)}$, потому что с с крышкой максимум из таких дробей. Значит, домножим на ненулевой знаменатель и получим $f(n) \leq \hat{c} \cdot g(n)$. 

Пусть $n \geq N$, тогда по построению $\hat{c} \geq c$. А нам дано, что $\forall n \geq N \rightarrow f(n) \leq c * g(n)$, значит подавно $\forall n \geq N \rightarrow f(n) \leq \hat{c} * g(n)$

"$\leftarrow$" $\ (f(n) \in O(g(n)) \leftarrow (\exists \hat{c} > 0: \forall n \in \mathbb{N} \rightarrow f(n) \leq \hat{c} \cdot g(n))$
То есть мы знаем, что выполняется правое, тогда нам надо предъявить такое $\hat{c}$, что существует такое $N$, что $\forall n \geq N$ выполняется соотношение $f(n) \leq \hat{c} \cdot g(n)$.

Ну положим $N = 1$, тогда по построению $\hat{c}$ понятно, что выполняется правое неравенство, тогда в частности для $N \geq 1$ это верно (потому что правое неравенство выполняется при всех $n$) и $c = \hat{c}$.
$\blacksquare$

#### Зачем мы это доказали?
Иногда алгоритм удобнее анализировать для $n$ начиная с некоторого, и уже для начиная с некоторого $n$ сказать уже какая асимптотика. 

Допустим имеем алгоритм, который особым образом перебирает маленькие $n$, а для начиная с $n \geq 10$ идет придуманный алгоритм, тогда можно не анализировать маленькие $n$ ведь мы доказали эквивалентность (всегда одна функция больше, чем другая).
#### Свойство 2
$\text{Пусть f, g: } \mathbb{N} \rightarrow \mathbb{N}$
$f(n) = O(g(n)), a > 0 \rightarrow a \cdot f(n) = O(g(n))$

*Получается, если умножить функцию на положительную константу, то её верхняя граница не меняется*
$\Box$
Дано: $f(n) = O(g(n)) \rightarrow \exists c > 0 \enspace \exists N \in \mathbb{N}: \forall n_0 \geq N \rightarrow f(n) \leq c \cdot g(n))$
Тогда умножим обе стороны неравенства на а и получим $a \cdot f(n) \geq ac \cdot g(n)$
Получили искомое: $a \cdot f(n) = O(g(n))$
$\blacksquare$
#### Свойство 3
Пусть $f_1, f_2, g_1, g_2: \mathbb{N} \rightarrow \mathbb{N}$
$f_1(n) = O(g_1(n)), f_2(n) = O(g_2(n)) \rightarrow f_1(n) + f_2(n) = O(\max({g_1(n), g_2(n)}))$
$\Box$
Дано:
$f_1(n) = O(g_1(n)) \rightarrow \exists c_1 > 0 \enspace \exists N_1 \in \mathbb{N}: \forall n_0 \geq N_1 \rightarrow f_1(n) \leq c_1 \cdot g_1(n))$
$f_2(n) = O(g_2(n)) \rightarrow \exists c_2 > 0 \enspace \exists N_2 \in \mathbb{N}: \forall n_0 \geq N_2 \rightarrow f_2(n) \leq c_2 \cdot g_2(n))$
Тогда сложим два неравенства с данными условиями:
$f_1(n) + f_2(n) \leq c_1 \cdot g_1(n) + c_2 \cdot g_2(n) \leq c_3 \cdot (g_1(n) + g_2(n)) \leq c_3 \cdot 2 \cdot \max{(g_1(n), g_2(n))}$, где $c_3 = \max{(c_1, c_2)}$. Получается, что с $N_3 = \max{(N_1, N_2)}$, будет выполняться неравенство. Получается предъявили такое с и такое N и такое с, что выполняется нужное неравнество

Получили цепочку неравенств, из которых можно сделать вывод: $f_1(n) + f_2(n) = O(\max({g_1(n), g_2(n)})$
$\blacksquare$
#### Свойство 4
Пусть $f_1, f_2, g_1, g_2: \mathbb{N} \rightarrow \mathbb{N}$
$f_1(n) = O(g_1(n)), f_2(n) = O(g_2(n)) \rightarrow f_1(n) \cdot f_2(n) = O(g_1(n) \cdot g_2(n))$
$\Box$
Дано:
$f_1(n) = O(g_1(n)) \rightarrow \exists c_1 > 0 \enspace \exists N_1 \in \mathbb{N}: \forall n_0 \geq N_1 \rightarrow f_1(n) \leq c_1 \cdot g_1(n))$
$f_2(n) = O(g_2(n)) \rightarrow \exists c_2 > 0 \enspace \exists N_2 \in \mathbb{N}: \forall n_0 \geq N_2 \rightarrow f_2(n) \leq c_2 \cdot g_2(n))$

Тогда перемножим два неравенства:
$f_1(n) \cdot f_2(n) \leq c_1 \cdot c_2 \cdot g_1(n) \cdot g_2(n) \leq c_3 \cdot g_1(n) \cdot g_2(n)$, получили, что при $c_3 = \max{(c_1, c_2)}$ и $N_3 = \max{(N_1, N_2)}$, выполняется такое неравенство, доказали 
$\blacksquare$

### Зачем доказали эти три свойства?
Доказав их, становится ясно, что:
1. $f(n) = an + b \text{ есть } O(n)$
2. $f(n) = b\log_{a}{n} + c \text{ есть } O(\log_{a}{n})$
	 **Важное замечание**: исходя из того факта, что все логарифмы подобны друг другу, можно опустить основание логарифма, потому что в нотации $О$-большое это не несет никакой смысловой нагрузки (Пишут: $O(\log{n})$)
3. $f(n) = a_kn^k + a_{k-1}n^{k-1} + ... + a_1n + a_0 \text{ есть } O(n^k)$
	 В частности это верно для квадратичной функции
4. Также: $a > 1, b > 1, a > b \rightarrow f(n) = a^n + b^n \text{ есть } O(a^n)$
### $O$-нотация для функций многих переменных
$\text{Пусть f, g: } \mathbb{N}^2 \rightarrow \mathbb{N}$
$$\ (f(n, q) \in O(g(n, q)) := (\exists c > 0:\forall n \in \mathbb{N}, \forall q \in \mathbb{N} \rightarrow f(n, q) \leq c \cdot g(n, q))$$

### Примечания
[[4. Скорость роста функций]]
